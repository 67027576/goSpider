## spider的自白

hey，大家好，我就是传说中的spider。经常在各个网络之间爬行，爬行了这么久，也算见过世面的了，现在我就给大家介绍一下我们spider一族的生活。

相信你经常听到爬虫爬虫，那么爬虫到底是什么呢?名字叫做spider 会不会感觉很神奇了，当然，你也可以叫我 `spider man!`

## 爬虫是什么

在回答这个问题之前，我们先探讨一下，爬虫能做什么。

- 获取网页上所看到数据。
- 模拟用户行为。
- 进行网络攻击。
- ...

从这些能做的事情中间，我们能看出，爬虫最关键的东西是 网络。

那么可知，网络知识是非常重要的。

因为网络知识比较大，也比较杂，为了即学即用，我们直接从最简单的爬虫代码开始吧。

## 第一次任务

hey，今天我又要去干活了，而且好像今天的活比较轻松。今天您就跟我一起参观一下我每天的工作吧！

今天的任务如下:

```
import requests

url = "http://www.baidu.com"
response = requests.get(url)
print(response.text)
```

这么简单吗！？

其实，这只是看着简单，那我们从正式的代码开始分析吧。

### 什么是网址

**url**

这个url到底是什么呢？

这个，可能还不能直接回答，我们还需要一点前置知识，网络(www)是怎么组成的。

#### 网络

电脑在最初的时候，都是一台一台，每台之间没有联系。但是，你写了一篇文章，我想看怎么办？

于是，软盘，U盘等存储介质就出现了。于是，你将你写的文章拷贝给了我，我在我的电脑上看了你的文章。

但是，我需要不停的对你的文章进行批注，你需要自己修改，需要不停的拷贝，黏贴，但是感觉太麻烦了。

于是想了一个办法，既然存储介质能和我的电脑互相连接，那么能不能让我的电脑和你的电脑连接起来呢？嗯，没错，网卡就出现啦！

这样我的电脑和你的电脑连接在了一起，可以通过网卡的通信，直接交换数据，方便太多了！



